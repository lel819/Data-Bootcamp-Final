# -*- coding: utf-8 -*-
"""eda

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iiK4a2rtXeb7cXhOM-X1ieKUtgWIH8Pt
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


from google.colab import files
upload = files.upload()
df = pd.read_csv('Pokemon.csv')
df.head()

#EDA

# stats of 'Total':
print("mean:", df['Total'].mean())
print("median:", df['Total'].median())
print("min:", df['Total'].min())
print("max:", df['Total'].max())

# box and whisker plot of 'Total'
sns.boxplot(data = df, x = 'Total')
plt.title('Box Plot of Total Stats')
plt.show()

# histogram of 'Total'
sns.histplot(data = df, x = 'Total')
plt.title('Histogram of Total Stats')
plt.show()

# plot HP (health points) with total stats
sns.scatterplot(data = df, x = 'HP', y = 'Total')
plt.title('Scatter Plot of HP vs Total')
plt.show()

# plot attack with total stats
sns.scatterplot(data = df, x = 'Attack', y = 'Total')
plt.title('Scatter Plot of Attack vs Total')
plt.show()

# plot defense with total stats
sns.scatterplot(data = df, x = 'Defense', y = 'Total')
plt.title('Scatter Plot of Defense vs Total')
plt.show()

# plot type1 with total stats
sns.barplot(data = df, x = 'Type 1', y = 'Total')
plt.title('Barplot of Type 1 vs Total')
plt.xticks(rotation=90)
plt.show()

# plot special attack with total stats
sns.scatterplot(data = df, x = 'Sp. Atk', y = 'Total')
plt.title('Scatter Plot of SP Atk vs Total')
plt.show()

# plot special defense with total stats
sns.scatterplot(data = df, x = 'Sp. Def', y = 'Total')
plt.title('Scatter Plot of SP Def vs Total')
plt.show()


# plot actual vs predicted values
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual Total')
plt.ylabel('Predicted Total Stats')
plt.title('KNN Regression: Actual vs Predicted Total Stats')
plt.tight_layout()
plt.show()


#get n_estimators values
n_estimators = [param['model__n_neighbors'] for param in grid_search.cv_results_['params']]

#mse scores
mse_scores = -grid_search.cv_results_['mean_test_score']

# plot MSE vs Number of Estimators
plt.figure(figsize=(10, 6))
plt.plot(n_estimators, mse_scores, marker='o', linestyle='-', color='b')
plt.xlabel('Number of Neighbors')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('MSE vs Number of Neighbors')
plt.grid(True)
plt.tight_layout()
plt.show()

# Get optimal depth
optimal_depth = grid_search.best_params_['max_depth']
print(f"Optimal depth from cross-validation: {optimal_depth}")
dtree.fit(X_train_encoded, y_train)

# Find optimal max depth
train_scores = []
test_scores = []
for d in range(1, 20):
    dtree = DecisionTreeRegressor(max_depth=d).fit(X_train_encoded, y_train)
    y_train_preds = dtree.predict(X_train_encoded)
    y_test_preds = dtree.predict(X_test_encoded)
    train_scores.append(mean_squared_error(y_train, y_train_preds))
    test_scores.append(mean_squared_error(y_test, y_test_preds))

# plot depth vs MSE
plt.figure(figsize=(10, 6))
plt.plot(range(1, 20), train_scores, '--o', label='train')
plt.plot(range(1, 20), test_scores, '--o', label='test')
plt.grid()
plt.legend()
plt.xticks(range(1, 20))
plt.xlabel('Max Tree Depth')
plt.ylabel('Mean Squared Error')
plt.title('Decision Tree Depth vs. Test/Train Accuracy')
plt.show()


#get the feature names
feature_names = encoder.get_feature_names_out().tolist()

plt.figure(figsize=(25, 15), facecolor='white')
plot_tree(
    dtree,
    feature_names=feature_names,
    filled=True,
    rounded=True,
    fontsize=10,
    proportion=True,
    precision=1,
    impurity=True
)

plt.title(f"Pokemon Stats Decision Tree (Max Depth: {optimal_depth})", fontsize=16, pad=20)
plt.tight_layout()
plt.show()

# plot actual vs predicted values
plt.figure(figsize=(12, 8))
plt.scatter(y_test, y_test_preds, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual Total Stats', fontsize = 12, labelpad = 10)
plt.ylabel('Predicted Total Stats', fontsize = 12, labelpad = 10)
plt.title('Decision Tree: Actual vs Predicted Total Stats', fontsize = 14)
plt.tight_layout()
plt.grid(True, linestyle='--', alpha=0.5)
plt.show()

# plot actual vs predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_test_preds, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual Total Stats')
plt.ylabel('Predicted Total Stats')
plt.title('Random Forest: Actual vs Predicted Total Stats')
plt.tight_layout()
plt.show()

# visualize feature importance
plt.figure(figsize=(10, 6))
importance_df.plot(kind='bar')
plt.title('Feature Importance in Random Forest Model')
plt.xlabel('Features')
plt.ylabel('Importance Score')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

